description: MANIFOLDLEARNING with CtP Experiments R2Plus1D on Kinetics (Pretrain) and Ucf (All/Linear Finetune(Adam))ï¼Œ MoCo Augmentation, proj 2048-256, bs 256 T 0.07, all finetune dropout 0.8, linear finetune lr 0.1, 1.0

target:
  service: amlk8s
  name: itplabrr1cl1
  vc: resrchvc

environment:
  image: wgting96/mmcv:pytorch1.7-cuda11.0-mmcv1.2.5

storage:
  data:
    storage_account_name: wu2train
    container_name: datasets

code:
  code_upload: True
  local_dir: $CONFIG_DIR/../../

jobs:

  - name: ML-wCtp-K400PUcfF-mocoaug-ep200-bs256-ts16-ss112-T0.07-proj-2048-256_ucf-ALFinetune-ep150-bs32-ts16-ss112_ModelR2p1dl18
    sku: G8
    command:
      - sudo ln -Ts $$PT_OUTPUT_DIR $$PT_CODE_DIR/output
      - export MKL_THREADING_LAYER=GNU
      - bash tools/dist_train.sh configs/manifoldlearning/r2plus1d_18_kinetics/pretraining.py 8 --data_dir /mnt/data
      - bash tools/dist_train.sh configs/manifoldlearning/r2plus1d_18_kinetics/finetune_ucf101.py 8 --data_dir /mnt/data --validate
      - bash tools/dist_train.sh configs/manifoldlearning/r2plus1d_18_kinetics/finetune_ucf101_linear.py 8 --data_dir /mnt/data --validate
      - bash tools/dist_train.sh configs/manifoldlearning/r2plus1d_18_kinetics/finetune_ucf101_linear_largeLR.py 8 --data_dir /mnt/data --validate

    # aml_mpirun:
    #   process_count_per_node: 1
    #   communicator: "OpenMpi"
    submit_args:
      container_args:
        shm_size: 64g
